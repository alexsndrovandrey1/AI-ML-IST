# Практическая работа 4

## Цель работы

1.  Изучить возможности СУБД DuckDB для обработки и анализ больших
    данных.

2.  Получить навыки применения DuckDB совместно с языком
    программирования R.

3.  Получить навыки анализа метаинфомации о сетевом трафике.

4.  Получить навыки применения облачных технологий хранения, подготовки
    и анализа данных: Yandex Object Storage, Rstudio Server.

## План

1.  Войдем в RStudio через SSH с использованием учетных данных
    пользователя.

2.  Выполним практическое задание.

3.  Составим отчет, в котором будет описан наш подход, результаты и
    выводы.

## Задание

Используя язык программирования R, СУБД и пакет duckdb и облачную IDE
Rstudio Server, развернутую в Yandex Cloud, выполнить задания и
составить отчет.

``` r
library(duckdb)
```

    Warning: пакет 'duckdb' был собран под R версии 4.3.3

    Загрузка требуемого пакета: DBI

``` r
library(dplyr)
```

    Warning: пакет 'dplyr' был собран под R версии 4.3.2


    Присоединяю пакет: 'dplyr'

    Следующие объекты скрыты от 'package:stats':

        filter, lag

    Следующие объекты скрыты от 'package:base':

        intersect, setdiff, setequal, union

``` r
library(tidyverse)
```

    Warning: пакет 'ggplot2' был собран под R версии 4.3.2

    ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──
    ✔ forcats   1.0.0     ✔ readr     2.1.4
    ✔ ggplot2   3.4.4     ✔ stringr   1.5.0
    ✔ lubridate 1.9.3     ✔ tibble    3.2.1
    ✔ purrr     1.0.2     ✔ tidyr     1.3.0

    ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
    ✖ dplyr::filter() masks stats::filter()
    ✖ dplyr::lag()    masks stats::lag()
    ℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors

``` r
connection <- dbConnect(duckdb::duckdb(), dbdir = ":memory:")
dbExecute(conn = connection, "INSTALL httpfs; LOAD httpfs;")
```

    [1] 0

``` r
PQF = "https://storage.yandexcloud.net/arrow-datasets/tm_data.pqt"
SQL <- "SELECT * FROM read_parquet([?])"
data <- dbGetQuery(connection, SQL, list(PQF))
```

### Задание 1: Надите утечку данных из Вашей сети.

Важнейшие документы с результатами нашей исследовательской деятельности
в области создания вакцин скачиваются в виде больших заархивированных
дампов. Один из хостов в нашей сети используется для пересылки этой
информации – он пересылает гораздо больше информации на внешние ресурсы
в Интернете, чем остальные компьютеры нашей сети.

``` r
zad1 <- data %>%
  filter(!grepl('^1[2-4].*', dst)) %>%
  group_by(src) %>%
  summarise(bytes_amount = sum(bytes)) %>%
  top_n(n = 1, wt = bytes_amount)
cat(zad1$src)
```

    13.37.84.125

filter(!grepl(‘^1\[2-4\].\*’, dst)): В этой строке происходит фильтрация
строк, где столбец dst не начинается с “12”, “13” или “14”. Функция
grepl используется для выполнения поиска по регулярному выражению, а
символ ^ обозначает начало строки. Оператор ! отрицает соответствие,
поэтому оставляются только строки, не соответствующие заданному шаблону.

group_by(src): В этой строке происходит группировка оставшихся строк по
столбцу src. Это означает, что последующие вычисления будут выполняться
для каждого уникального значения в столбце src.

summarise(bytes_amount = sum(bytes)): В этой строке вычисляется сумма
столбца bytes для каждой группы (уникального значения в столбце src).
Результат сохраняется в новом столбце с именем bytes_amount.

top_n(n = 1, wt = bytes_amount): В этой строке выбирается верхняя строка
на основе столбца bytes_amount. Параметр n указывает, что нужно оставить
только верхнюю строку, а параметр wt указывает столбец, по которому
определяется верхняя строка.

Определите его IP-адрес - 13.37.84.125.

### Задание 2: Надите утечку данных 2.

Другой атакующий установил автоматическую задачу в системном
планировщике cron для экспорта содержимого внутренней wiki системы. Эта
система генерирует большое количество трафика в нерабочие часы, больше
чем остальные хосты.

Определите IP этой системы. Известно, что ее IP адрес отличается от
нарушителя из предыдущей задачи.

``` r
zad2 <- data %>%
  select(timestamp, src, dst, bytes) %>%
  mutate(timestamp = hour(as_datetime(timestamp/1000))) %>%
  filter(!grepl('^1[2-4].*', dst) & timestamp >= 0 & timestamp <= 15) %>%
  group_by(src) %>%
  summarise(bytes_amount = sum(bytes)) %>%
  filter(src != "13.37.84.125") %>%
  top_n(1, wt = bytes_amount)

cat(zad2$src)
```

    12.55.77.96

select(timestamp, src, dst, bytes): Выбираем только столбцы timestamp,
src, dst и bytes из фрейма данных df. Это позволяет нам работать только
с необходимыми столбцами данных.

mutate(timestamp = hour(as_datetime(timestamp/1000))): С помощью функции
mutate преобразуем столбец timestamp в часовой формат. Для этого мы
сначала делим значения столбца на 1000, чтобы привести их к
миллисекундам, а затем используем функции as_datetime и hour для
преобразования временных меток в часы.

filter(!grepl(‘^1\[2-4\].\*’, dst) & timestamp \>= 0 & timestamp \<=
15): Фильтруем строки данных, исключая строки, где значение столбца dst
начинается с “12”, “13” или “14”. Используем регулярное выражение для
поиска соответствующих значений. Также фильтруем строки, где значение
столбца timestamp находится в диапазоне от 0 до 15, что соответствует
нерабочим часам.

group_by(src): Группируем данные по уникальным значениям в столбце src,
чтобы производить агрегацию на уровне каждого отправителя.

summarise(bytes_amount = sum(bytes)): С помощью функции summarise
создаем новый столбец bytes_amount, содержащий суммарное значение
столбца bytes для каждого отправителя.

filter(src != “13.37.84.125”): Исключаем строки, где значение столбца
src равно “13.37.84.125”, чтобы исключить известный IP-адрес.

top_n(1, wt = bytes_amount): Выбираем только одну строку с наибольшим
значением bytes_amount с помощью функции top_n. Это позволяет нам найти
IP-адрес с наибольшим объемом трафика в нерабочие часы.

Определите IP этой системы. Известно, что ее IP адрес отличается от
нарушителя из предыдущей задачи - 12.55.77.96

### Задание 3: Надите утечку данных 3.

Еще один нарушитель собирает содержимое электронной почты и отправляет в
Интернет используя порт, который обычно используется для другого типа
трафика. Атакующий пересылает большое количество информации используя
этот порт, которое нехарактерно для других хостов, использующих этот
номер порта.

``` r
zad3 <- data %>%
  select(src, port, dst, bytes) %>%
  filter(!str_detect(dst, '1[2-4].')) %>%
  group_by(src, port) %>%
  summarise(bytes_ip_port = sum(bytes), .groups = "drop") %>%
  group_by(port) %>%
  mutate(average_port_traffic = mean(bytes_ip_port)) %>%
  ungroup() %>%
  top_n(1, bytes_ip_port / average_port_traffic)
cat(zad3$src)
```

    12.30.96.87

Определите IP этой системы. Известно, что ее IP адрес отличается от
нарушителей из предыдущих задач - 12.30.96.87

### Задание 4: Обнаружение канала управления.

Зачастую в корпоротивных сетях находятся ранее зараженные системы,
компрометация которых осталась незамеченной. Такие системы генерируют
небольшое количество трафика для связи с панелью управления бот-сети, но
с одинаковыми параметрами – в данном случае с одинаковым номером порта.

``` r
zad4 <- data%>%
  group_by(port) %>%
  summarise(minBytes = min(bytes),
            maxBytes = max(bytes),
            diffBytes = max(bytes) - min(bytes),
            avgBytes = mean(bytes),
            count = n()) %>%
  filter(avgBytes - minBytes < 10 & minBytes != maxBytes) %>%
  select(port)
zad4
```

    # A tibble: 1 × 1
       port
      <int>
    1   124

group_by(port) - группирует данные по столбцу port, чтобы выполнить
агрегацию на уровне каждого уникального значения port.

summarise(minBytes = min(bytes), maxBytes = max(bytes), diffBytes =
max(bytes) - min(bytes), avgBytes = mean(bytes), count = n()) -
выполняет агрегацию данных, где:

minBytes - минимальное значение в столбце bytes в каждой группе.
maxBytes - максимальное значение в столбце bytes в каждой группе.
diffBytes - разница между максимальным и минимальным значениями в
столбце bytes в каждой группе. avgBytes - среднее значение в столбце
bytes в каждой группе. count - количество строк в каждой группе.
filter(avgBytes - minBytes \< 10 & minBytes != maxBytes) - фильтрует
результаты, оставляя только те группы, где разница между средним и
минимальным значением bytes меньше 10 и минимальное значение bytes не
равно максимальному.

select(port) - выбирает только столбец port в итоговом результате.

Какой номер порта используется бот-панелью для управления ботами - 124

### Задание 5: Обнаружение P2P трафика.

Иногда компрометация сети проявляется в нехарактерном трафике между
хостами в локальной сети, который свидетельствует о горизонтальном
перемещении (lateral movement).

В нашей сети замечена система, которая ретранслирует по локальной сети
полученные от панели управления бот-сети команды, создав таким образом
внутреннюю пиринговую сеть.

Какой уникальный порт используется этой бот сетью для внутреннего
общения между собой?

### Задание 6: Чемпион малвари.

Нашу сеть только что внесли в списки спам-ферм. Один из хостов сети
получает множество команд от панели C&C, ретранслируя их внутри сети. В
обычных условиях причин для такого активного взаимодействия внутри сети
у данного хоста нет.

Определите IP такого хоста.

## Вывод

Были изучены возможности СУБД DuckDB для обработки и анализа больших
данных. DuckDB позволяет эффективно работать с большими объемами данных,
обеспечивая высокую скорость выполнения запросов.

Были получены навыки работы с DuckDB в сочетании с языком
программирования R. С использованием пакета duckdb в R, были выполнены
запросы к базе данных DuckDB, а также проведен анализ данных с
применением соответствующих функций и операций.

Были получены навыки анализа метаинформации о сетевом трафике. С помощью
анализа данных о сетевом трафике, была определена информация о бот-сети,
внутреннем общении между ботами, а также наиболее активном хосте внутри
сети.

Были получены навыки работы с облачными технологиями хранения,
подготовки и анализа данных, такими как Yandex Object Storage и Rstudio
Server. Было осуществлено хранение данных в облаке, подготовка и анализ
данных с использованием соответствующих инструментов и платформ.
